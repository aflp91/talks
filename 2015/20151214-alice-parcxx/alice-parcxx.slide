Introduction to parallel programming
MRRTF, 2015/12/14

Sebastien Binet
CNRS/IN2P3/LPC
binet@cern.ch

* Disclaimer

I used to be a `C++` programmer, then a `python` programmer.

Nowadays, I am a [[https://golang.org][Go]] programmer at heart, enjoying blazing fast compilation time, builtin concurrency constructs, easy installation and deployment, etc...

I really learned parallel/concurrent programming with `Go`.
My views on parallel programming with `C++` are thus somewhat skewed.

.image figs/gopher.png
.caption The Go mascott: a gopher

* Parallel programming

Parallel programming is hard.
Parallel programming is harder in `C++`.

Actually, are we really sure we want to do *parallel* programming ?

* Concurrency vs Parallelism

_Concurrency:_ programming as the composition of independently executing processes/tasks.

_Parallelism:_ programming as the simultaneous execution of (possibly related) computations.

.image figs/conc-vs-par.png 350 _

* Concurrency vs Parallelism

Concurrency is about dealing with lots of things at once.
Parallelism is about doing lots of things at once.

Concurrency is about (program) *structure*.
Parallelism is about (program) *execution*.

.image figs/conc-vs-par-prog.png 350 _

* Concurrency vs Parallelism

Concurrency and parallelism are related.
Concurrency isn't parallelism (it's better!)

Parallelizing an application is done by:

- finding concurrency in the problem
- exposing the concurrency in the source code
- exploiting the exposed concurrency to complete the job in less time.

.image figs/conc-vs-par-decomp.png

* Decomposition in parallel programs

Every parallel program is based on concurrency
i.e: tasks defined by an application that can run at the same time.

*EVERY* parallel program requires a _task_decomposition_ and a _data_decomposition_:

- Task decomposition: break the application down into a set of tasks that can execute concurrently.
- Data decomposition: How must the data be broken down into chunks and associated with threads/processes to make the parallel program run efficiently.

* Goldilocks

Parallel approaches have to find the "sweet spot" between two extremes.

Too fine grained:

- Data: computation dominated by overhead
- Tasks: context switching overhead

Too coarse grained:

- Data: load balancing problems
- Tasks: insufficient items to keep processes busy

* Parallel programming: multi-process vs multi-threaded

Multi-process:

- resource requirements are multiplied w/ nbr of process instances
- (clever) use of `fork(2)` can mitigate this issue (but not in a `MT` environment)
- one process can not corrupt the memory of another process
- overhead of pushing data from one process to the other

Multi-threaded:

- small context switch times (wrt an OS' process)
- automatic sharing of many hardware resources (memory, fds, sockets...)
- thread-safety of external libraries?
- one thread can corrupt another thread

`FairRoot` design can cater for both (`MP` _via_ `ZeroMQ` or `NanoMQ` message queues)

* Multi-threading & Multi-processing in a C++ world

Modern architectures impose massive challenges on programmability in the context of performance portability.

- massive increase in on-node parallelism
- deep memory hierarchies

Only *portable* parallelization solution for `C++` programmers (today?): *OpenMP* & *MPI*

- hugely successful for years
- widely used and supported
- simple use for simple cases
- very portable
- highly optimized

_Which_ `C++` BTW ?

* C++ timeline

`C++` is a wide and complex language.
Know your `C++` and the (subset of?) `C++` you are *allowed* to write!

- `C++03`?
- `C++11`?
- `C++14`?

.image figs/wg21-timeline.png 300 _

* Parallelism in C++

`C++11` introduced lower level abstractions:

- `std::thread`, `std::mutex`, `std::future`, ...
- fairly limited, more is needed
- `C++` needs stronger support for higher-level parallelism

Several proposals to the Standardization Committee are accepted or under consideration:

- Technical Specification: Concurrency
- Technical Specification: Parallelism
- Other smaller proposals: resumable functions, task regions, executors

* Parallelism in C++

Currently, there is no overarching vision related to higher-level parallelism

- goal is to standardize on a "big story" by 2020
- no need for OpenMP, OpenACC, OpenCL, etc...

But for the moment, `C++` programmers are stuck with `C++11/14`...

* Memory model

With `C++11`, finally `C++` has a memory model that contemplates a multi-threaded execution of a program.

A thread is a single flow of control within a program

- Every thread can potentially access every object and function in the program
- The interleaving of each thread's instructions is undefined

.image figs/thread-exec-race.png

* Memory model

`C++` guarantees that two threads can update and access *separate* memory locations without interfering with each other.

- For all other situations updates and accesses have to be properly synchronized
  - atomics, locks, memory fences
- If updates and accesses to the same location by multiple threads are not properly synchronized, there is a data race
  - undefined behavior
- Data races can be made visible by transformations applied by the compiler or by the processor for performance reasons

* FairMQ + docker

Running the `FairMQ` example 2 with `docker` (you need 3 terminals):

 term-1> docker run -it --rm --name=ex2-fair hepsw/alice-fair bash
 term-2> docker exec -it ex2-fair bash
 term-3> docker exec -it ex2-fair bash

In `term-1`, create `/data/ex2-sample-process-sink.json` from [[https://github.com/FairRootGroup/FairRoot/blob/master/examples/MQ/2-sampler-processor-sink/ex2-sampler-processor-sink.json][ex2-sample-process-sink.json]]:

 term-1> curl -L \
  https://raw.githubusercontent.com/FairRootGroup/FairRoot/master/examples/MQ/2-sampler-processor-sink/ex2-sampler-processor-sink.json \
  > /data/ex2-sampler-processor-sink.json

Then:

 term-1> ex2-sampler --id sampler1 \
         --config-json-file /data/ex2-sampler-processor-sink.json
 term-2> ex2-sink --id sink1 \
         --config-json-file /data/ex2-sampler-processor-sink.json
 term-3> ex2-processor --id processor2
         --config-json-file /data/ex2-sampler-processor-sink.json

* FairMQ - term-1

 term-1> ex2-sampler --id sampler1 \
         --config-json-file /data/ex2-sampler-processor-sink.json 
 [16:22:24][STATE] Entering FairMQ state machine
 [...]
 [16:22:24][STATE] Entering INITIALIZING DEVICE state
 [16:22:24][DEBUG] Validating channel "data-out[0]"... VALID
 [16:22:24][DEBUG] Initializing channel data-out[0] (push)
 [16:22:24][DEBUG] Binding channel data-out[0] on tcp://*:5555
 [16:22:25][STATE] Entering DEVICE READY state
 [16:22:25][STATE] Entering INITIALIZING TASK state
 [16:22:25][STATE] Entering READY state
 [16:22:25][STATE] Entering RUNNING state
 [16:22:25][INFO] DEVICE: Running...
 [16:22:26][INFO] Sending "Hello"
  
* FairMQ - term-2

 term-2> ex2-sink --id sink1 --config-json-file /data/ex2-sampler-processor-sink.json 
 [16:24:33][STATE] Entering FairMQ state machine
 [...]
 [16:24:33][STATE] Entering INITIALIZING DEVICE state
 [16:24:33][DEBUG] Validating channel "data-in[0]"... VALID
 [16:24:33][DEBUG] Initializing channel data-in[0] (pull)
 [16:24:33][DEBUG] Binding channel data-in[0] on tcp://*:5556
 [16:24:34][STATE] Entering DEVICE READY state
 [16:24:34][STATE] Entering INITIALIZING TASK state
 [16:24:34][STATE] Entering READY state
 [16:24:34][STATE] Entering RUNNING state
 [16:24:34][INFO] DEVICE: Running...

* FairMQ - term-3

 term-3> ex2-processor --id processor2 --config-json-file /data/ex2-sampler-processor-sink.json 
 [16:26:30][STATE] Entering FairMQ state machine
 [...]
 [16:26:30][STATE] Entering INITIALIZING DEVICE state
 [16:26:30][DEBUG] Validating channel "data-out[0]"... VALID
 [16:26:30][DEBUG] Initializing channel data-out[0] (push)
 [16:26:30][DEBUG] Connecting channel data-out[0] to tcp://localhost:5556
 [16:26:30][DEBUG] Validating channel "data-in[0]"... VALID
 [16:26:30][DEBUG] Initializing channel data-in[0] (pull)
 [16:26:30][DEBUG] Connecting channel data-in[0] to tcp://localhost:5555
 [16:26:31][STATE] Entering DEVICE READY state
 [16:26:31][STATE] Entering INITIALIZING TASK state
 [16:26:31][STATE] Entering READY state
 [16:26:31][STATE] Entering RUNNING state
 [16:26:31][INFO] DEVICE: Running...
 [16:26:31][INFO] Received data, processing...
 [16:26:31][INFO] Received data, processing...
 [16:26:32][INFO] Received data, processing...
 [16:26:33][INFO] Received data, processing...
 [16:26:34][INFO] Received data, processing...
 ^C
 [16:26:35][INFO] Caught signal 2
 [16:26:35][DEBUG] Closed all sockets!
 [16:26:35][INFO] Exiting.

* FairMQ

When `processor2` is run, the chain is complete and processing can start:

 [term-1]
 [16:22:25][INFO] DEVICE: Running...
 [16:22:26][INFO] Sending "Hello"
 [16:26:31][INFO] Sending "Hello"
 [16:26:32][INFO] Sending "Hello"
 [16:26:33][INFO] Sending "Hello"
 [16:26:34][INFO] Sending "Hello"
 [16:26:35][INFO] Sending "Hello"

 [term-2]
 [16:26:31][INFO] Received message: "Hello (modified by processor2)"
 [16:26:31][INFO] Received message: "Hello (modified by processor2)"
 [16:26:32][INFO] Received message: "Hello (modified by processor2)"
 [16:26:33][INFO] Received message: "Hello (modified by processor2)"
 [16:26:34][INFO] Received message: "Hello (modified by processor2)"
 
- 6 "Hello" data packets are send over the wire
- 5 packets are processed by `processor2` (before `^C` was hit)
- 5 packets are displayed by `sink1`

