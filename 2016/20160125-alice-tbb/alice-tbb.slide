Introduction to Thread Building Blocks

MRRTF, 2016-01-25

Sebastien Binet
CNRS/IN2P3/LPC
binet@cern.ch

* Recap from last episode

* C++11 std::thread

`C++11` (finally!) standardized threads

- `std::thread` is now part of the standard `C++` library
- `std::thread` is an abstraction and maps to local platform threads (`POSIX`, `Windows(TM)`, ...)

* C++11 std::thread

.code code/hello-par.cxx

 $> g++ -o hello-par --std=c++11 -pthread hello-par.cxx
 $> ./hello-par
 ** inside thread 139800850654976!
 
* Programming style

- Old school: thread functions (what we just saw)
- Middle school: function objects (functors)
- New school: `C++11` lambda functions (aka anonymous functions)

* Types of parallelism

Most common types:

- Data
- Task
- Embarrassingly parallel
- Dataflow

* C++ concurrency features

.image figs/cxx-features.png

* Futures

*Futures* provide a higher level of abstraction

- you start an asynchronous/parallel operation
- you are returned a handle to wait for the result
- thread creation, join and exceptions are handled for you

* Async tasks and futures

.code code/async.cxx

- access the result via the `get()` method
- one can also use `wait()` to block the thread until the result is available (but doesn't read the result)

* Intel Threading Building Blocks

* Intel TBB - Introduction

Open source project (GPLv2) for supporting scalable parallel programming `C++`.

It is a *higher* *level* toolkit than `C++11` threads.

"If it's suitable to your problem, then it's almost certainly a better choice."

`TBB` supports common programming patterns for loops:

- `parallel_for` for independent computations on arrays
- `parallel_reduce` for a series of computations across an array
- `parallel_scan` for more general prefix calculations.

See the [[https://software.intel.com/en-us/node/506140][documentation]] for a complete list.

`TBB` also provides thread-safe containers, a performant thread safe memory allocator and timing primitives.

* Intel TBB - Introduction (cont'd)


`TBB` also allows the construction of *graphs* describing the relationship between different parts of a program's execution and the `TBB` *scheduler* can exploit concurrency where different parts of the workflow are independent.

Further, for *task* based workflows, `TBB` allows lower level interaction with its task scheduler, enabling it to be used as an execution engine for a higher level workflow generator.

*Using* *TBB*.

- include the header `"tbb/tbb.h"`
- link against `-ltbb` (and, on `Linux`, against `-lrt`)
- `TBB` identifiers are under the `tbb::` namespace.

* Parallel loop algorithms

* Parallel for

Simple parallel operation where the same operation is performed independently over elements of a collection.

Serially:

  for (size_t i=0; i<array_size; ++i) {
     my_func(x[i]);
  }

With `TBB`, to turn this sequential loop into a parallel one, one needs to express the operation as a _callable_ object, which can take a special `TBB` template class' instance as an argument.

* Parallel for - II

 #include "tbb/tbb.h"
 
 class ApplyFunc {
     double *const my_x;
 public:
     void operator()(const tbb::blocked_range<size_t>& r) const {
         double *x = my_x;
         for(size_t i=r.begin(); i!=r.end(); ++i)
             my_func(x[i]);
     }
     ApplyFunc(double x[]):
         my_x{x}
     {}
 };

The `tbb::blocked_range<size_t>` parameter is used by `TBB` to instruct threads to operate on a certain chunk of the `my_x` array.

* Parallel for - III

With `ApplyFunc` defined, one can now invoke `tbb::parallel_for` like so:

 #include "tbb/tbb.h"
 
 void ParallelApplyFunc(double x[], size_t n) {
     tbb::parallel_for(tbb::blocked_range<size_t>(0, n), ApplyFunc(x));
 }

In this case `parallel_for` is instructed to run over the range `[0,n)` on the `ApplyFunc(x)` class instance.

Note that `parallel_for` will take care of setting up the `TBB` thread pool for us (in earlier versions of `TBB`, one needed to call `tbb::task_scheduler_init`, which is still available if you need to setup the `TBB` thread pool with special options).

* Parallel for - IV

As for the `std::thread` case, one can also use a lambda function instead of a functor:

.code code/tbb-parallel-for-lambda.cxx

Using the lambda which copies by value `[=]` satisfies all the criteria needed by `parallel_for` and makes for a very succinct declaration.

* Parallel reduce

`parallel_for` is great for when operations applied to elements of a collection are *independent*.
But, there are cases where the operation needs input from the previous steps.
If the computation can still be broken down into pieces, we can still parallelize this operation, which is called a *reduction*.

Here's a simple example: if one needs to sum up 10 numbers one can do it like this

  (((((((((1+2)+3)+4)+5)+6)+7)+8)+9)+10)

which is sequential. But one could also do it like this:

  ((1+2) + (3+4)) + ((5+6) + ((7+8) + (9+10)))

where it's now much easier to see that the calculation can be parallelized.
There are some extra steps needed here:

- how to *split* the whole collection into smaller chunks
- how to *join* the results of the smaller chunks into aggregated results.

* Parallel reduce - II

.code code/tbb-parallel-reduce.cxx

* Parallel reduce - III

Notice the two new methods that were needed

- A special constructor that takes a reference to an existing `parallel_sum` instance and a special dummy parameter `tbb::split`. This is the *splitting* *constructor* that `TBB` uses to generate new parts of the *reduction* that will run on other threads. (The dummy variable distinguishes this method from the class's copy constructor.)
- A `join` method that tells `TBB` how to *combine* the results from one fragment of the reduction with another (in this case, just adding up the partial sums).

Once the class is ready, we invoke the reduction by calling `parallel_reduce`:

.code code/tbb-parallel-reduce-use.cxx

Note that because of the extra methods that are needed for `parallel_reduce` it's less easy to use a lambda here.

* Different blocked range templates

`blocked_range` is designed for `1D` collections.
However, many times we need to deal with more complicated objects than that.
So here we can use `blocked_range2d` or `blocked_range3d` to iterate.

For a `blocked_range2d<T>` r, instead of using `r.begin()` we have `r.rows().begin()` and `r.cols().begin()` (likewise for `end()`).

So a fragment of a matrix multiply would be something like:

.code code/tbb-matrix-mult.cxx

* Containers

`STL` containers are not thread safe.
Reading them in parallel is fine.
But as soon as one thread modifies a container while other threads access it: *corruption*.

`STL` containers need to be guarded with a `std::mutex` for concurrent r/w access.
`STL` containers thus are usually bottlenecks in multithreaded applications.

`TBB` provides concurrency friendly containers with most of the features one can expect of their `STL` counterparts.
There are two strategies to make such containers:

- Use lock-free techniques, which correct for any interference between threads automatically.
- Use fine grained locking, where only the part of the container which is being touched is wrapped in a mutex.

* Concurrent vector

`concurrent_vector<T>`:

- allows dynamic growth of an array of type `T`.

- can be grown safely while other threads are accessing it, including growing it themselves.

.code code/vec-add.cxx

- clearing or destroying the vector and accessing it is *unsafe*.
- `size()` returns the size of all elements, even those being constructed, so accessing those elements might be problematic.
- unlike an `std::vector`, elements in a concurrent vector are not guaranteed to be contiguous in memory.

* Other containers

`TBB` provides many other concurrent containers, including hash maps and queues. We won't cover them here, but having practiced with the concurrent vector you should find them pretty easy to use.

- `tbb::concurrent_unordered_map`
- `tbb::concurrent_unordered_set`
- `tbb::concurrent_hash_map`
- `tbb::concurrent_queue`

* Pipelines and graphs

Many real-world problems can be addressed with `TBB` `parallel_for`, `parallel_reduce` and more [[https://software.intel.com/en-us/node/506140][sophisticated patterns]].
But `TBB` also allows for parallelization based on *task* *workflows*.

_Pipelines_ are a simple execution concept.
- Tasks to be executed come in a linear sequence, much like an assembly line.
- Each incoming piece of data is processed by the first element of the pipeline, then the second and so on.
- Serial process for any data element.
- Parallelism arises because we can have many pieces of data moving through the pipeline at the one time.

* Pipelines

 +---------+
 |  Start  | <- data1, data2, data3, ..., dataN
 +---------+
     |
     V
 +---------+
 | Stage 1 |
 +---------+
     |
     V
 +---------+
 | Stage 2 |
 +---------+
     |
     V
 +---------+
 |  Stop   | -> outN, ... , out3, out2, out1
 +---------+

* Pipelines

- Each stage can either be serial or parallel.
- No more than one element will be processed by serial stages at a time.
- Serial stages can be in order or out of order.

- Multiple elements can be processed by parallel stages at the same time
- Ordering is obviously not guaranteed.

Considering the performance one might hope to get with a pipeline, obviously the serial stages are bottlenecks (especially serial in order), so keeping these stages short will help a lot.


* Defining a Pipeline

Pipelines are defined as a series of _filters_, each of which takes some input data and produces some transformed output data.
The first filter's input data is `void`, as is the last filter's output data.

.code code/pipeline.cxx

`ntoken` prevents data from piling up at the choke point of the pipeline and consuming resources needlessly.

* How a Pipeline runs

`TBB` actually runs the pipeline by calling the `()` `operator` of each filter for the data element that is going to be processed.

e.g., our `Transform` class might look like this:

.code code/pipeline-transform.cxx

Note that as the `()` `operator` might be called on a copy of the original class instance it needs to be `const` to ensure it does not make changes to the body which would be lost in the copy.

* How a Pipeline runs - II

Similarly, the `DataWriter` could look like:

.code code/pipeline-datawriter.cxx

The first stage is a bit more complicated as it needs a mechanism to tell the pipeline there is no more data to process.
This is what the special `tbb::flow_control` class is for.

* How a Pipeline runs - III

.code code/pipeline-datareader.cxx

* TBB Graphs

The most general kind of task based workflow is a graph, where tasks are nodes and edges are data that flows between the nodes.

 +---------+
 |  Start  | <- data1, data2, data3, ..., dataN
 +---------+--------------
     |      \             \
     V       \             \
 +---------+  \|            \
 | Node 1  |   +--------+    +--------+
 +---------+   | Node 2 |    | Node 4 |
     |         +--------+    +--------+
     V              |             |
 +---------+        |             |
 | Node 3  |        |             |
 +---------+        |             |
     |              |             |
     |   +----------+-------------+
     |   |
     V   V
 +---------+
 |  Node 5 | -> out1, out2, out3, ..., outN
 +---------+

* TBB Graphs - II

Graphs are a very flexible way to execute tasks in parallel.
`TBB` has many node types that allow for processing, splitting, joining, queueing etc.
Note also that although the ASCII art example there is a `DAG` (Directed Acyclic Graph), `TBB` can implement graphs with cycles as well.

The Intel [[https://software.intel.com/en-us/node/517340][documentation]] has a good introduction.

